{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.aisultan.xyz/swlh/sentiment-analysis-from-scratch-with-logistic-regression-ca6f119256ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets =twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets =twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "example_postive_tweet=positive_tweets[0]\n",
    "example_negative_tweet=negative_tweets[0]\n",
    "\n",
    "test_pos = positive_tweets[4000:]\n",
    "train_pos = positive_tweets[:4000]\n",
    "\n",
    "test_neg = negative_tweets[4000:]\n",
    "train_neg = negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                  \n",
    "import string\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "def process_tweet(tweet):\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tweet_tokenized = tokenizer.tokenize(tweet)\n",
    "    stopwords_english = stopwords.words('english') \n",
    "    tweet_processsed=[word for word in tweet_tokenized \n",
    "    if word not  in stopwords_english and word not in       \n",
    "    string.punctuation]\n",
    "    stemmer = PorterStemmer() \n",
    "    tweet_after_stem=[]\n",
    "    for word in tweet_processsed:\n",
    "        word=stemmer.stem(word)\n",
    "        tweet_after_stem.append(word)\n",
    "    return tweet_after_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words=[]\n",
    "for tweet in positive_tweets:\n",
    "    tweet=process_tweet(tweet)\n",
    "    \n",
    "    for word in tweet:\n",
    "        \n",
    "        pos_words.append(word)\n",
    "freq_pos={}\n",
    "for word in pos_words:\n",
    "    if (word,1) not in freq_pos:\n",
    "        freq_pos[(word,1)]=1\n",
    "    else:\n",
    "        freq_pos[(word,1)]=freq_pos[(word,1)]+1\n",
    "neg_words=[]\n",
    "for tweet in negative_tweets:\n",
    "    tweet=process_tweet(tweet)\n",
    "    \n",
    "    for word in tweet:\n",
    "        \n",
    "        neg_words.append(word)\n",
    "freq_neg={}\n",
    "for word in neg_words:\n",
    "    if (word,0) not in freq_neg:\n",
    "        freq_neg[(word,0)]=1\n",
    "    else:\n",
    "        freq_neg[(word,0)]=freq_neg[(word,0)]+1\n",
    "        \n",
    "freqs_dict = dict(freq_pos)\n",
    "freqs_dict.update(freq_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(tweet, freqs_dict):\n",
    "    word_l = process_tweet(tweet)\n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1 \n",
    "    for word in word_l:\n",
    "        try:\n",
    "            x[0,1] += freqs_dict[(word,1)]\n",
    "        except:\n",
    "            x[0,1] += 0\n",
    "        try: \n",
    "            x[0,2] += freqs_dict[(word,0.0)]\n",
    "        except:\n",
    "            x[0,2] += 0\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x\n",
    "\n",
    "X = np.zeros((len(train_x), 3))\n",
    "    \n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    X[i, :]= features_extraction(train_x[i], freqs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    h = 1/(1+np.exp(-x))\n",
    "    return h\n",
    "\n",
    "def gradientDescent_algo(x, y, theta, alpha, num_iters):\n",
    "    m = x.shape[0]\n",
    "    for i in range(0, num_iters):\n",
    "        z = np.dot(x,theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1/m*(np.dot(y.T,np.log(h))+np.dot((1-y).T,np.log(1-h)))\n",
    "        theta = theta-(alpha/m)*np.dot(x.T,h-y)\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= features_extraction(train_x[i], freqs_dict)\n",
    "Y = train_y\n",
    "J, theta = gradientDescent_algo(X, Y, np.zeros((3, 1)), 1e-9, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984\n"
     ]
    }
   ],
   "source": [
    "def predict(tweet, freqs_dict, theta):\n",
    "    x = features_extraction(tweet,freqs_dict)\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    return y_pred\n",
    "def test_accuracy(test_x, test_y, freqs_dict, theta):\n",
    "    y_hat = []\n",
    "    for tweet in test_x:\n",
    "        \n",
    "        y_pred = predict(tweet, freqs_dict, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "           \n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            \n",
    "            y_hat.append(0)\n",
    "    m=len(y_hat)\n",
    "    y_hat=np.array(y_hat)\n",
    "    y_hat=y_hat.reshape(m)\n",
    "    test_y=test_y.reshape(m)\n",
    "    \n",
    "    c=y_hat==test_y\n",
    "    j=0\n",
    "    for i in c:\n",
    "        if i==True:\n",
    "            j=j+1\n",
    "    accuracy = j/m\n",
    "    return accuracy\n",
    "accuracy = test_accuracy(test_x, test_y, freqs_dict, theta)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('dl': conda)",
   "language": "python",
   "name": "python38264bitdlcondaa180a010ef684b4caaeb2a04b88c216b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
