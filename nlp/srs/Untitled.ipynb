{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import nltk.classify.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.stem import PorterStemmer        \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>movie_link</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>review_subtitle</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>/film/178563/</td>\n",
       "      <td>/user/311869/</td>\n",
       "      <td>sochi2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Настоящее кино. Наше кино. Прекрасная работа с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>/film/178563/</td>\n",
       "      <td>/user/1591566/</td>\n",
       "      <td>Альберт Попов</td>\n",
       "      <td>Предтеча многого</td>\n",
       "      <td>Мало того, что сериал «Империя под ударом» (12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>/film/178563/</td>\n",
       "      <td>/user/331395/</td>\n",
       "      <td>LennoxL</td>\n",
       "      <td>Срез жизни общества начала 20 го века</td>\n",
       "      <td>Период от реформ Александра Освободителя до пе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>/film/178563/</td>\n",
       "      <td>/user/4379604/</td>\n",
       "      <td>Ana_K</td>\n",
       "      <td>Пусть мир погибнет, но восторжествует правосудие</td>\n",
       "      <td>Атмосферный сериал о Российской Империи начала...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/film/178563/</td>\n",
       "      <td>/user/178788/</td>\n",
       "      <td>Skept</td>\n",
       "      <td>Террор  Зло с непредсказуемыми последствиями</td>\n",
       "      <td>Самая большая беда современного общества это т...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target     movie_link       author_id    author_name  \\\n",
       "0     good  /film/178563/   /user/311869/      sochi2014   \n",
       "1     good  /film/178563/  /user/1591566/  Альберт Попов   \n",
       "2     good  /film/178563/   /user/331395/        LennoxL   \n",
       "3     good  /film/178563/  /user/4379604/          Ana_K   \n",
       "4  neutral  /film/178563/   /user/178788/          Skept   \n",
       "\n",
       "                                    review_subtitle  \\\n",
       "0                                               NaN   \n",
       "1                                 Предтеча многого\n",
       "   \n",
       "2             Срез жизни общества начала 20 го века   \n",
       "3  Пусть мир погибнет, но восторжествует правосудие   \n",
       "4    Террор  Зло с непредсказуемыми последствиями\n",
       "   \n",
       "\n",
       "                                         review_text  \n",
       "0  Настоящее кино. Наше кино. Прекрасная работа с...  \n",
       "1  Мало того, что сериал «Империя под ударом» (12...  \n",
       "2  Период от реформ Александра Освободителя до пе...  \n",
       "3  Атмосферный сериал о Российской Империи начала...  \n",
       "4  Самая большая беда современного общества это т...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('reviews.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80284, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_link</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>review_subtitle</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>7281</td>\n",
       "      <td>7281</td>\n",
       "      <td>7281</td>\n",
       "      <td>5475</td>\n",
       "      <td>7281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>60189</td>\n",
       "      <td>60189</td>\n",
       "      <td>60187</td>\n",
       "      <td>46500</td>\n",
       "      <td>60187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>12814</td>\n",
       "      <td>12814</td>\n",
       "      <td>12814</td>\n",
       "      <td>8225</td>\n",
       "      <td>12814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie_link  author_id  author_name  review_subtitle  review_text\n",
       "target                                                                   \n",
       "bad            7281       7281         7281             5475         7281\n",
       "good          60189      60189        60187            46500        60187\n",
       "neutral       12814      12814        12814             8225        12814"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['target']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сразу хотелось бы честно признаться: не досмотрел до конца даже первую серию. Простите, не смог. Можно сколько угодно рассуждать о ценности данного фильма, об актерских работах и подборе звезд, но не заметить факта, что отсебятина хлещет через край, невозможно.\n",
      "\r\n",
      "Если есть люди, прочитавшие книгу, они поймут моё отношение к данной экранизации. С самого начала идут какие-то придуманные диалоги и реплики, которых не должно быть по сути. Задача сценаристов была сложная, но её облегчили донельзя. Ни одна сцена не избежала изменений. Прежде чем снимать, нужно было, во-первых, несколько раз прочитать роман, во-вторых, глубоко понять его психологию. О чем можно говорить, если у Фантины одна подруга, она знает о беременности и вовсеуслышание это говорит? Господа, у Гюго и близко такого не было! Минус 5 из плюс 10 возможных.\n",
      "\r\n",
      "Обратимся к образу епископа. Он в книге никогда не поручал другому то, что мог сделать сам, он описан совершенным ангелом во плоти (со своими маленькими мсинусами, естественно). Он бы не стал говорить кому-то посмотреть что происходит в саду, а проверил бы лично (к слову, он и матрасы бы собственноручно перетаскал, наверное). Неужели так сложно было подумать над образом?\n",
      "\r\n",
      "Ладно, перейдем к образу Жана Вальжана. Первое: нельзя брать на роль каторжника актера, пусть и заслуженного, но с таким явным пузом и отъетой ряхой. Чтобы зритель поверил в 19 лет каторги не достаточно побрить голову Депардье наголо. Второе: он какой-то обиженный и надувшийся хлюпик, толстячок, у которого отобрали бутерброд, а не обозлившийся человек со сложной судьбой, переживший в душе множество метаний то в одну, то в другую сторону. Об остальных персонажах писать не буду, так как не досмотрел. В общем, троечка всем.\n",
      "\r\n",
      "Подводя итог хотел бы пожелать сценаристам, режиссеру и актерам читать оригинал, много раз читать, прежде чем браться за столь монументальное полотно, которое они опрометчиво перекроили как душе было угодно. Картина вызывает ассоциации шедевра величины микеланджеловского Давида, которую дети попытались сделать в песочнице. Ставлю 3 из 10.\n"
     ]
    }
   ],
   "source": [
    "print(negative_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_80 = (df.shape[0] * 80) // 100\n",
    "\n",
    "positive_reviews = df[df['target'] == 'good']['review_text'].astype('str').to_numpy()\n",
    "negative_reviews = df[df['target'] == 'bad']['review_text'].astype('str').to_numpy()\n",
    "neutral_reviews = df[df['target'] == 'neutral']['review_text'].astype('str').to_numpy()\n",
    "\n",
    "example_positive_review = positive_reviews[0]\n",
    "example_negative_review = negative_reviews[0]\n",
    "example_neutral_review = neutral_reviews[0]\n",
    "\n",
    "test_pos = positive_reviews[df_80:]\n",
    "train_pos = positive_reviews[:df_80]\n",
    "\n",
    "test_neg = negative_reviews[df_80:]\n",
    "train_neg = negative_reviews[:df_80]\n",
    "\n",
    "test_neu = neutral_reviews[df_80:]\n",
    "train_neu = neutral_reviews[:df_80]\n",
    "\n",
    "train_x = np.concatenate((train_pos, train_neg, train_neu))\n",
    "test_x = np.concatenate((test_pos, test_neg, test_neu))\n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)),  axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def review_process(review):\n",
    "#     review = re.sub(r'[^0-9а-яА-ЯёЁ]+', ' ', review)\n",
    "#     tokenizer = TweetTokenizer()\n",
    "#     review_tokenized = tokenizer.tokenize(review)\n",
    "#     stopwords = nltk.corpus.stopwords.words(\"russian\")\n",
    "#     review_processsed = [word for word in review_tokenized if word not  in stopwords and word not in string.punctuation]\n",
    "#     stemmer = PorterStemmer() \n",
    "#     review_after_stem = []\n",
    "#     for word in review_processsed:\n",
    "#         word = stemmer.stem(word)\n",
    "#         review_after_stem.append(word)\n",
    "#     return review_after_stem\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^0-9а-яА-ЯёЁ]+', ' ', text)\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = nltk.corpus.stopwords.words(\"russian\")\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text data\n",
    "reviews_df[\"review_clean\"] = reviews_df[\"review\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words, neg_words, freq_pos, freq_neg = np.array([]), np.array([]), {}, {}\n",
    "\n",
    "for review in positive_reviews[:1000]:\n",
    "    review = review_process(review)\n",
    "    pos_words = np.append(pos_words, review)\n",
    "\n",
    "for word in pos_words:\n",
    "    if (word, 1) not in freq_pos:\n",
    "        freq_pos[(word, 1)] = 1\n",
    "    else:\n",
    "        freq_pos[(word, 1)] = freq_pos[(word, 1)] + 1\n",
    "\n",
    "for review in negative_reviews[:1000]:\n",
    "    review = review_process(review)\n",
    "    neg_words = np.append(neg_words, review)\n",
    "        \n",
    "for word in neg_words:\n",
    "    if (word,0) not in freq_neg:\n",
    "        freq_neg[(word,0)] = 1\n",
    "    else:\n",
    "        freq_neg[(word,0)] = freq_neg[(word,0)] + 1\n",
    "        \n",
    "freqs_dict = dict(freq_pos)\n",
    "freqs_dict.update(freq_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(review, freqs_dict):\n",
    "    word_l = review_process(review)\n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1 \n",
    "    for word in word_l:\n",
    "        try:\n",
    "            x[0,1] += freqs_dict[(word, 1)]\n",
    "        except:\n",
    "            x[0,1] += 0\n",
    "        try: \n",
    "            x[0,2] += freqs_dict[(word, 0.0)]\n",
    "        except:\n",
    "            x[0,2] += 0\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x\n",
    "\n",
    "X = np.zeros((len(train_x[:1000]), 3))\n",
    "    \n",
    "for i in range(len(train_x[:1000])):\n",
    "    X[i, :]= features_extraction(train_x[i], freqs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "    h = 1/(1 + np.exp(-x))\n",
    "    return h\n",
    "\n",
    "def gradientDescent_algo(x, y, theta, alpha, num_iters):\n",
    "    m = x.shape[0]\n",
    "    for i in range(0, num_iters):\n",
    "        z = np.dot(x,theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1/m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h)))\n",
    "        theta = theta - (alpha/m) * np.dot(x.T,h-y)\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,67470) and (1000,1) not aligned: 67470 (dim 1) != 1000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d9f5fddcc882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradientDescent_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-37aadca6b7a7>\u001b[0m in \u001b[0;36mgradientDescent_algo\u001b[0;34m(x, y, theta, alpha, num_iters)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,67470) and (1000,1) not aligned: 67470 (dim 1) != 1000 (dim 0)"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(train_x[:1000]), 3))\n",
    "for i in range(len(train_x[:1000])):\n",
    "    X[i, :] = features_extraction(train_x[i], freqs_dict)\n",
    "Y = train_y\n",
    "J, theta = gradientDescent_algo(X, Y, np.zeros((3, 1)), 1e-9, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tweet, freqs_dict, theta):\n",
    "    x = features_extraction(tweet,freqs_dict)\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    return y_pred\n",
    "def test_accuracy(test_x, test_y, freqs_dict, theta):\n",
    "    y_hat = []\n",
    "    for tweet in test_x:\n",
    "        \n",
    "        y_pred = predict(tweet, freqs_dict, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "           \n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            \n",
    "            y_hat.append(0)\n",
    "    m=len(y_hat)\n",
    "    y_hat=np.array(y_hat)\n",
    "    y_hat=y_hat.reshape(m)\n",
    "    test_y=test_y.reshape(m)\n",
    "    \n",
    "    c=y_hat==test_y\n",
    "    j=0\n",
    "    for i in c:\n",
    "        if i==True:\n",
    "            j=j+1\n",
    "    accuracy = j/m\n",
    "    return accuracy\n",
    "accuracy = test_accuracy(test_x, test_y, freqs_dict, theta)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('dl': conda)",
   "language": "python",
   "name": "python38264bitdlcondaa180a010ef684b4caaeb2a04b88c216b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
